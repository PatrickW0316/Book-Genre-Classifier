{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "pip install wikipedia-api pandas tqdm"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "C4hfbafxFpxF",
        "outputId": "384f8765-6cb7-418c-ce53-4563ccb59c5f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: wikipedia-api in /usr/local/lib/python3.11/dist-packages (0.8.1)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.11/dist-packages (2.2.2)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (4.67.1)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from wikipedia-api) (2.32.3)\n",
            "Requirement already satisfied: numpy>=1.23.2 in /usr/local/lib/python3.11/dist-packages (from pandas) (2.0.2)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas) (2025.1)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas) (2025.1)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas) (1.17.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->wikipedia-api) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->wikipedia-api) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->wikipedia-api) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->wikipedia-api) (2025.1.31)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Rb4sFuw05zJj",
        "outputId": "2eb35e8e-293e-4456-d4ed-16602be6612e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fetching Fiction books...\n",
            "Total fiction books fetched: 5000\n",
            "Fetching Non-fiction books...\n",
            "Total non-fiction books fetched: 5000\n",
            "Extracting summaries for fiction books...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 5000/5000 [14:09<00:00,  5.88it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting summaries for non-fiction books...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 5000/5000 [14:28<00:00,  5.76it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                               Title  \\\n",
            "0  Master of the Universe (Twilight)   \n",
            "1                             Nazgûl   \n",
            "2             Process of Elimination   \n",
            "3                     Septima Vector   \n",
            "4                 Barthanes Damodred   \n",
            "\n",
            "                                             Summary Category  \n",
            "0  Fifty Shades of Grey is a 2011 erotic romance ...  Fiction  \n",
            "1  The Nazgûl (from Black Speech nazg 'ring', and...  Fiction  \n",
            "2  Super Mystery is a 36-volume series of crossov...  Fiction  \n",
            "3  The following is a list of characters from the...  Fiction  \n",
            "4  The Wheel of Time is a series of high fantasy ...  Fiction  \n",
            "Dataset size: 10000 entries.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ],
      "source": [
        "import wikipediaapi\n",
        "import pandas as pd\n",
        "from tqdm import tqdm\n",
        "\n",
        "wiki = wikipediaapi.Wikipedia(user_agent='BookSummaryDatasetGenerator/1.0 (ziyiwan@umich.edu)', language='en')\n",
        "\n",
        "# Define categories to scrape\n",
        "fiction_category = \"Category:Novels_by_genre\"\n",
        "nonfiction_category = \"Category:Non-fiction_books\"\n",
        "\n",
        "# Function to recursively get book titles from categories\n",
        "def get_books(category, limit=5000):\n",
        "    titles = set()\n",
        "\n",
        "    def recursive_scrape(cat, titles_set):\n",
        "        for c in cat.categorymembers.values():\n",
        "            if len(titles_set) >= limit:\n",
        "                break\n",
        "            if c.ns == wikipediaapi.Namespace.MAIN:\n",
        "                titles_set.add(c.title)\n",
        "            elif c.ns == wikipediaapi.Namespace.CATEGORY:\n",
        "                recursive_scrape(c, titles_set)\n",
        "\n",
        "    cat_page = wiki.page(category)\n",
        "    recursive_scrape(cat_page, titles)\n",
        "\n",
        "    return list(titles)\n",
        "\n",
        "# Fetch books from each category\n",
        "print(\"Fetching Fiction books...\")\n",
        "fiction_books = get_books(fiction_category, limit=5000)\n",
        "print(f\"Total fiction books fetched: {len(fiction_books)}\")\n",
        "\n",
        "print(\"Fetching Non-fiction books...\")\n",
        "nonfiction_books = get_books(nonfiction_category, limit=5000)\n",
        "print(f\"Total non-fiction books fetched: {len(nonfiction_books)}\")\n",
        "\n",
        "# Function to get summary\n",
        "def get_summary(title):\n",
        "    page = wiki.page(title)\n",
        "    if page.exists():\n",
        "        summary = page.summary.split(\"\\n\")[0]  # first paragraph\n",
        "        return summary\n",
        "    else:\n",
        "        return None\n",
        "\n",
        "# Create dataset\n",
        "data = []\n",
        "\n",
        "print(\"Extracting summaries for fiction books...\")\n",
        "for title in tqdm(fiction_books):\n",
        "    summary = get_summary(title)\n",
        "    if summary:\n",
        "        data.append({\"Title\": title, \"Summary\": summary, \"Category\": \"Fiction\"})\n",
        "\n",
        "print(\"Extracting summaries for non-fiction books...\")\n",
        "for title in tqdm(nonfiction_books):\n",
        "    summary = get_summary(title)\n",
        "    if summary:\n",
        "        data.append({\"Title\": title, \"Summary\": summary, \"Category\": \"Non-fiction\"})\n",
        "\n",
        "# Save dataset\n",
        "df = pd.DataFrame(data)\n",
        "df.to_csv(\"wikipedia_books_dataset.csv\", index=False)\n",
        "print(df.head())\n",
        "print(f\"Dataset size: {len(df)} entries.\")\n"
      ]
    }
  ]
}